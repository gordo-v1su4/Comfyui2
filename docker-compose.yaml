version: '3.8'

# Named volumes for persistent data
volumes:
  models-storage:
    driver: local
  custom-nodes-storage:
    driver: local

services:
  # Main ComfyUI service
  comfyui:
    build: .
    container_name: comfyui-easy-install
    ports:
      - "8188:8188"
    volumes:
      # Instance-specific storage (local)
      - ./output:/app/ComfyUI/output
      - ./input:/app/ComfyUI/input
      - ./temp:/app/ComfyUI/temp
      - ./user:/app/ComfyUI/user
      
      # Model and Custom Node storage
      - models-storage:/app/ComfyUI/models
      - custom-nodes-storage:/app/ComfyUI/custom_nodes
    environment:
      - PYTHONUNBUFFERED=1
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      # GPU settings - required for GPU passthrough
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # S3/MinIO configuration to connect to EXISTING MinIO instance
      - COMFYUI_S3_ENABLED=${COMFYUI_S3_ENABLED:-false}
      - MINIO_ENDPOINT=${MINIO_ENDPOINT:-http://minio:9000}
      - MINIO_ACCESS_KEY=${SERVICE_USER_MINIO:-minioadmin}
      - MINIO_SECRET_KEY=${SERVICE_PASSWORD_MINIO:-minioadmin123}
      - MINIO_BUCKET_MODELS=${MINIO_BUCKET_MODELS:-ai-models}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8188/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # GPU runtime - required for NVIDIA GPU support
    runtime: nvidia
